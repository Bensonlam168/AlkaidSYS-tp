# AlkaidSYS æ•°æ®è¿ç§»

## ğŸ“‹ æ–‡æ¡£ä¿¡æ¯

| é¡¹ç›® | å†…å®¹ |
|------|------|
| **æ–‡æ¡£åç§°** | AlkaidSYS æ•°æ®è¿ç§» |
| **æ–‡æ¡£ç‰ˆæœ¬** | v1.0 |
| **åˆ›å»ºæ—¥æœŸ** | 2025-01-19 |

## ğŸ¯ æ•°æ®è¿ç§»ç›®æ ‡

1. **é›¶åœæœºè¿ç§»** - æœ€å°åŒ–ä¸šåŠ¡ä¸­æ–­æ—¶é—´
2. **æ•°æ®å®Œæ•´æ€§** - ç¡®ä¿æ•°æ®å®Œæ•´æ— ä¸¢å¤±
3. **å¯å›æ»š** - æ”¯æŒå¿«é€Ÿå›æ»šåˆ°è¿ç§»å‰çŠ¶æ€
4. **æ€§èƒ½ä¼˜åŒ–** - å¤§æ•°æ®é‡è¿ç§»æ€§èƒ½ä¼˜åŒ–

## ğŸ—ï¸ æ•°æ®è¿ç§»æ¶æ„

> è¯´æ˜ï¼šæœ¬ç¯‡æ–‡æ¡£ä»â€œæ‰§è¡Œå±‚é¢â€æè¿°å…·ä½“è¿ç§»æµç¨‹å’Œè„šæœ¬ç¤ºä¾‹ï¼Œæ˜¯å¯¹
> ã€Š03-data-layer/11-database-evolution-and-migration-strategy.mdã€‹ä¸
> ã€Š03-data-layer/13-data-evolution-bluebook.mdã€‹æ‰€å®šä¹‰çš„æ•°æ®æ¼”è¿›æµç¨‹çš„è½åœ°è¡¥å……ï¼›
> ä¸Šè¿°ä¸¤ä»½æ–‡æ¡£ä»ç„¶æ˜¯æ•°æ®æ¼”è¿›ä¸å˜æ›´æµç¨‹çš„æƒå¨æ¥æºï¼Œå®é™…è¿ç§»æ–¹æ¡ˆä¸æ£€æŸ¥æ¸…å•å¦‚æœ‰å·®å¼‚ä»¥å®ƒä»¬ä¸ºå‡†ã€‚


```mermaid
graph TB
    subgraph "è¿ç§»å‡†å¤‡"
        A[æ•°æ®è¯„ä¼°]
        B[è¿ç§»æ–¹æ¡ˆ]
        C[æµ‹è¯•ç¯å¢ƒéªŒè¯]
    end

    subgraph "è¿ç§»æ‰§è¡Œ"
        D[æ•°æ®å¤‡ä»½]
        E[å¢é‡åŒæ­¥]
        F[å…¨é‡è¿ç§»]
        G[æ•°æ®éªŒè¯]
    end

    subgraph "è¿ç§»å®Œæˆ"
        H[åˆ‡æ¢æµé‡]
        I[ç›‘æ§è§‚å¯Ÿ]
        J[æ¸…ç†æ—§æ•°æ®]
    end

    A --> B --> C
    C --> D --> E --> F --> G
    G --> H --> I --> J
```

## ğŸ“Š è¿ç§»ç­–ç•¥

### 1. è¿ç§»æ–¹æ¡ˆé€‰æ‹©

| æ–¹æ¡ˆ | é€‚ç”¨åœºæ™¯ | åœæœºæ—¶é—´ | å¤æ‚åº¦ |
|------|---------|---------|--------|
| **å…¨é‡è¿ç§»** | æ•°æ®é‡å°ï¼ˆ< 10GBï¼‰ | 2-4 å°æ—¶ | ä½ |
| **å¢é‡è¿ç§»** | æ•°æ®é‡ä¸­ç­‰ï¼ˆ10-100GBï¼‰ | < 1 å°æ—¶ | ä¸­ |
| **åŒå†™è¿ç§»** | æ•°æ®é‡å¤§ï¼ˆ> 100GBï¼‰ | å‡ ä¹ä¸º 0 | é«˜ |

### 2. è¿ç§»æ—¶é—´è¡¨

```mermaid
gantt
    title AlkaidSYS æ•°æ®è¿ç§»æ—¶é—´è¡¨
    dateFormat  YYYY-MM-DD
    section å‡†å¤‡é˜¶æ®µ
    æ•°æ®è¯„ä¼°           :2025-01-20, 3d
    è¿ç§»æ–¹æ¡ˆè®¾è®¡       :2025-01-23, 2d
    æµ‹è¯•ç¯å¢ƒéªŒè¯       :2025-01-25, 3d
    section è¿ç§»é˜¶æ®µ
    æ•°æ®å¤‡ä»½           :2025-01-28, 1d
    å¢é‡åŒæ­¥           :2025-01-29, 2d
    å…¨é‡è¿ç§»           :2025-01-31, 1d
    æ•°æ®éªŒè¯           :2025-02-01, 1d
    section å®Œæˆé˜¶æ®µ
    æµé‡åˆ‡æ¢           :2025-02-02, 1d
    ç›‘æ§è§‚å¯Ÿ           :2025-02-03, 3d
    æ¸…ç†æ—§æ•°æ®         :2025-02-06, 1d
```

## ğŸ”§ è¿ç§»å·¥å…·

### 1. æ•°æ®å¯¼å‡ºå·¥å…·

```php
<?php
// /app/command/DataExport.php

namespace app\command;

use think\console\Command;
use think\console\Input;
use think\console\Output;
use think\facade\Db;

class DataExport extends Command
{
    protected function configure()
    {
        $this->setName('data:export')
            ->setDescription('å¯¼å‡ºæ•°æ®åˆ° JSON æ–‡ä»¶');
    }

    protected function execute(Input $input, Output $output)
    {
        $output->writeln('å¼€å§‹å¯¼å‡ºæ•°æ®...');

        $tables = [
            'tenants',
            'sites',
            'users',
            'roles',
            'permissions',
            'products',
            'orders',
        ];

        $exportDir = root_path() . 'runtime/export/' . date('YmdHis');
        if (!is_dir($exportDir)) {
            mkdir($exportDir, 0755, true);
        }

        foreach ($tables as $table) {
            $output->writeln("å¯¼å‡ºè¡¨: {$table}");
            $this->exportTable($table, $exportDir);
        }

        $output->writeln('æ•°æ®å¯¼å‡ºå®Œæˆï¼');
        $output->writeln("å¯¼å‡ºç›®å½•: {$exportDir}");
    }

    /**
     * å¯¼å‡ºå•ä¸ªè¡¨
     */
    protected function exportTable(string $table, string $exportDir): void
    {
        $pageSize = 1000;
        $page = 1;
        $total = Db::table($table)->count();
        $totalPages = ceil($total / $pageSize);

        $file = fopen("{$exportDir}/{$table}.json", 'w');
        fwrite($file, "[\n");

        while ($page <= $totalPages) {
            $offset = ($page - 1) * $pageSize;
            $data = Db::table($table)
                ->limit($offset, $pageSize)
                ->select()
                ->toArray();

            foreach ($data as $index => $row) {
                $json = json_encode($row, JSON_UNESCAPED_UNICODE);
                fwrite($file, "  {$json}");

                if ($page < $totalPages || $index < count($data) - 1) {
                    fwrite($file, ",\n");
                } else {
                    fwrite($file, "\n");
                }
            }

            $page++;
        }

        fwrite($file, "]");
        fclose($file);
    }
}
```

### 2. æ•°æ®å¯¼å…¥å·¥å…·

```php
<?php
// /app/command/DataImport.php

namespace app\command;

use think\console\Command;
use think\console\Input;
use think\console\input\Argument;
use think\console\Output;
use think\facade\Db;

class DataImport extends Command
{
    protected function configure()
    {
        $this->setName('data:import')
            ->addArgument('dir', Argument::REQUIRED, 'å¯¼å…¥ç›®å½•')
            ->setDescription('ä» JSON æ–‡ä»¶å¯¼å…¥æ•°æ®');
    }

    protected function execute(Input $input, Output $output)
    {
        $dir = $input->getArgument('dir');

        if (!is_dir($dir)) {
            $output->error("ç›®å½•ä¸å­˜åœ¨: {$dir}");
            return;
        }

        $output->writeln('å¼€å§‹å¯¼å…¥æ•°æ®...');

        $tables = [
            'tenants',
            'sites',
            'users',
            'roles',
            'permissions',
            'products',
            'orders',
        ];

        foreach ($tables as $table) {
            $file = "{$dir}/{$table}.json";
            if (!file_exists($file)) {
                $output->warning("æ–‡ä»¶ä¸å­˜åœ¨: {$file}");
                continue;
            }

            $output->writeln("å¯¼å…¥è¡¨: {$table}");
            $this->importTable($table, $file);
        }

        $output->writeln('æ•°æ®å¯¼å…¥å®Œæˆï¼');
    }

    /**
     * å¯¼å…¥å•ä¸ªè¡¨
     */
    protected function importTable(string $table, string $file): void
    {
        $json = file_get_contents($file);
        $data = json_decode($json, true);

        if (!$data) {
            return;
        }

        // åˆ†æ‰¹æ’å…¥
        $batchSize = 500;
        $batches = array_chunk($data, $batchSize);

        Db::startTrans();
        try {
            foreach ($batches as $batch) {
                Db::table($table)->insertAll($batch);
            }
            Db::commit();
        } catch (\Exception $e) {
            Db::rollback();
            throw $e;

        }
    }
}
```

### 3. æ•°æ®éªŒè¯å·¥å…·

> è¯´æ˜ï¼šä»¥ä¸‹ DataValidate ç¤ºä¾‹ä»…æ¼”ç¤ºå‘½ä»¤éª¨æ¶ï¼Œå®é™…å®ç°æ—¶åº”ç»“åˆã€Š03-data-layer/12-multi-tenant-data-model-spec.mdã€‹ã€Š01-architecture-design/04-multi-tenant-design.mdã€‹ï¼Œ
> å¯¹ `tenant_id`ã€`site_id` ç­‰å…³é”®å­—æ®µçš„å­˜åœ¨æ€§ã€å¼•ç”¨å®Œæ•´æ€§ä»¥åŠè·¨åº“/è·¨è¡¨ä¸€è‡´æ€§è¿›è¡Œæ ¡éªŒï¼Œå¹¶ä¾æ®ä¸šåŠ¡è¡¨è¡¥å……æ›´å¤šæ ¡éªŒè§„åˆ™ã€‚

```php
<?php
// /app/command/DataValidate.php
namespace app\command;

use think\console\Command;
use think\console\Input;
use think\console\Output;
use think\facade\Db;

class DataValidate extends Command
{
    protected function configure()
    {
        $this->setName('data:validate')
            ->setDescription('éªŒè¯æ•°æ®å®Œæ•´æ€§');
    }

    protected function execute(Input $input, Output $output)
    {
        $output->writeln('å¼€å§‹éªŒè¯æ•°æ®...');

        $tables = [
            'tenants',
            'sites',
            'users',
            'roles',
            'permissions',
            'products',
            'orders',
        ];

        $errors = [];

        foreach ($tables as $table) {
            $output->writeln("éªŒè¯è¡¨: {$table}");
            $tableErrors = $this->validateTable($table);
            if ($tableErrors) {
                $errors[$table] = $tableErrors;
            }
        }

        if (empty($errors)) {
            $output->writeln('<info>æ•°æ®éªŒè¯é€šè¿‡ï¼</info>');
        } else {
            $output->writeln('<error>æ•°æ®éªŒè¯å¤±è´¥ï¼</error>');
            foreach ($errors as $table => $tableErrors) {
                $output->writeln("è¡¨ {$table}:");
                foreach ($tableErrors as $error) {
                    $output->writeln("  - {$error}");
                }
            }
        }
    }

    /**
     * éªŒè¯å•ä¸ªè¡¨
     */
    protected function validateTable(string $table): array
    {
        $errors = [];

        // æ£€æŸ¥è®°å½•æ•°
        $count = Db::table($table)->count();
        if ($count === 0) {
            $errors[] = 'è¡¨ä¸ºç©º';
        }

        // æ£€æŸ¥ä¸»é”®é‡å¤
        $duplicates = Db::table($table)
            ->field('id')
            ->group('id')
            ->having('COUNT(*) > 1')
            ->select();

        if ($duplicates->count() > 0) {
            $errors[] = 'å­˜åœ¨é‡å¤çš„ä¸»é”®';
        }

        // æ£€æŸ¥å¿…å¡«å­—æ®µ
        $requiredFields = $this->getRequiredFields($table);
        foreach ($requiredFields as $field) {
            $nullCount = Db::table($table)
                ->whereNull($field)
                ->count();

            if ($nullCount > 0) {
                $errors[] = "å­—æ®µ {$field} å­˜åœ¨ {$nullCount} æ¡ç©ºå€¼";
            }
        }

        return $errors;
    }

    /**
     * è·å–å¿…å¡«å­—æ®µ
     */
    protected function getRequiredFields(string $table): array
    {
        $fields = [
            'tenants' => ['code', 'name'],
            'sites' => ['tenant_id', 'code', 'name'],
            'users' => ['tenant_id', 'username', 'email'],
            'roles' => ['tenant_id', 'name', 'code'],
            'permissions' => ['name', 'code'],
            'products' => ['tenant_id', 'site_id', 'name', 'price'],
            'orders' => ['tenant_id', 'site_id', 'user_id', 'order_no', 'amount'],
        ];

        return $fields[$table] ?? [];
    }
}
```

## ğŸ“ è¿ç§»è„šæœ¬

> é‡è¦è¯´æ˜ï¼ˆè®¾è®¡é˜¶æ®µï¼‰ï¼šæœ¬èŠ‚ Shell è„šæœ¬å‡ä¸º**ç¤ºä¾‹è„šæœ¬**ï¼Œç”¨äºè¯´æ˜æ¨èçš„è¿ç§»æ­¥éª¤ä¸é¡ºåºï¼š
> - dev/test ç¯å¢ƒå¯ä»¥ç›´æ¥ç”¨äºæ¼”ç»ƒä¸éªŒè¯ï¼›
> - stage/prod ç¯å¢ƒå¿…é¡»å…ˆç»è¿‡ DBA ä¸è¿ç»´è¯„å®¡ï¼ŒæŒ‰å…¬å¸æ ‡å‡†å˜æ›´æµç¨‹æ”¹é€ ï¼ˆä¾‹å¦‚æ›¿æ¢ `root` è´¦æˆ·ã€è¡¥å……å®¡è®¡ä¸é™æµã€é¿å…åœ¨ç”Ÿäº§æœºä¸Šç›´æ¥æ‰§è¡Œ `mysqldump`/`mysql`/`systemctl` ç­‰å‘½ä»¤ï¼‰ã€‚
> å®é™…è½åœ°æ—¶ï¼Œåº”ä»¥ã€Š03-data-layer/11-database-evolution-and-migration-strategy.mdã€‹ã€Š03-data-layer/13-data-evolution-bluebook.mdã€‹ä¸­å…³äºå˜æ›´å®¡æ‰¹ã€æ¼”ç»ƒä¸å›æ»šçš„æµç¨‹ä¸å®‰å…¨ç­–ç•¥ä¸ºå‡†ã€‚
### 1. å…¨é‡è¿ç§»è„šæœ¬

```bash
#!/bin/bash
# /scripts/migrate-full.sh

set -e

echo "========================================="
echo "AlkaidSYS å…¨é‡æ•°æ®è¿ç§»"
echo "========================================="

# é…ç½®
SOURCE_DB="alkaid_old"
TARGET_DB="alkaid_new"
BACKUP_DIR="/data/backup/$(date +%Y%m%d%H%M%S)"

# 1. å¤‡ä»½æºæ•°æ®åº“
echo "1. å¤‡ä»½æºæ•°æ®åº“..."
mkdir -p $BACKUP_DIR
mysqldump -u root -p --single-transaction --routines --triggers --events --databases $SOURCE_DB > $BACKUP_DIR/source.sql
echo "å¤‡ä»½å®Œæˆ: $BACKUP_DIR/source.sql"

# 2. å¯¼å‡ºæ•°æ®
echo "2. å¯¼å‡ºæ•°æ®..."
php think data:export

# 3. åˆ›å»ºç›®æ ‡æ•°æ®åº“
echo "3. åˆ›å»ºç›®æ ‡æ•°æ®åº“..."
mysql -u root -p -e "CREATE DATABASE IF NOT EXISTS $TARGET_DB CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;"

# 4. å¯¼å…¥è¡¨ç»“æ„
echo "4. å¯¼å…¥è¡¨ç»“æ„..."
# æ³¨æ„ï¼šè¯·å…ˆå°† .env ä¸­çš„ DB_DATABASE æŒ‡å‘ $TARGET_DB å†æ‰§è¡Œè¿ç§»
php think migrate:run

# 5. å¯¼å…¥æ•°æ®
echo "5. å¯¼å…¥æ•°æ®..."
EXPORT_DIR=$(ls -t runtime/export | head -1)
php think data:import runtime/export/$EXPORT_DIR

# 6. éªŒè¯æ•°æ®
echo "6. éªŒè¯æ•°æ®..."
php think data:validate

# 7. å®Œæˆ
echo "========================================="
echo "è¿ç§»å®Œæˆï¼"
echo "========================================="
```

### 2. å¢é‡è¿ç§»è„šæœ¬

```bash
#!/bin/bash
# /scripts/migrate-incremental.sh

set -e

echo "========================================="
echo "AlkaidSYS å¢é‡æ•°æ®è¿ç§»"
echo "========================================="

# é…ç½®
SOURCE_DB="alkaid_old"
TARGET_DB="alkaid_new"
LAST_SYNC_TIME=$(cat /tmp/last_sync_time 2>/dev/null || echo "1970-01-01 00:00:00")

echo "ä¸Šæ¬¡åŒæ­¥æ—¶é—´: $LAST_SYNC_TIME"

# 1. åŒæ­¥æ–°å¢æ•°æ®
echo "1. åŒæ­¥æ–°å¢æ•°æ®..."
# ä½¿ç”¨ mysqldump ç”Ÿæˆ INSERT è¯­å¥å¹¶å¯¼å…¥
mysqldump -u root -p --single-transaction --no-create-info --skip-triggers $SOURCE_DB users --where="created_at > '$LAST_SYNC_TIME'" > /tmp/users_insert.sql
mysql -u root -p $TARGET_DB < /tmp/users_insert.sql

# 2. åŒæ­¥æ›´æ–°æ•°æ®
echo "2. åŒæ­¥æ›´æ–°æ•°æ®..."
# åŒæ­¥æ›´æ–°æ•°æ®ï¼ˆä½¿ç”¨ REPLACE å¤„ç†ä¸»é”®å†²çªï¼‰
mysqldump -u root -p --single-transaction --no-create-info --skip-triggers --replace $SOURCE_DB users --where="updated_at > '$LAST_SYNC_TIME'" > /tmp/users_update.sql
mysql -u root -p $TARGET_DB < /tmp/users_update.sql

# 3. æ›´æ–°åŒæ­¥æ—¶é—´
echo "3. æ›´æ–°åŒæ­¥æ—¶é—´..."
date "+%Y-%m-%d %H:%M:%S" > /tmp/last_sync_time

echo "========================================="
echo "å¢é‡åŒæ­¥å®Œæˆï¼"
echo "========================================="
```

## ğŸ”„ å›æ»šæ–¹æ¡ˆ

### å›æ»šè„šæœ¬

```bash
#!/bin/bash
# /scripts/rollback.sh

set -e

echo "========================================="
echo "AlkaidSYS æ•°æ®å›æ»š"
echo "========================================="

# é…ç½®
BACKUP_DIR=$1

if [ -z "$BACKUP_DIR" ]; then
    echo "é”™è¯¯: è¯·æŒ‡å®šå¤‡ä»½ç›®å½•"
    echo "ç”¨æ³•: ./rollback.sh /data/backup/20250119120000"
    exit 1
fi

if [ ! -f "$BACKUP_DIR/source.sql" ]; then
    echo "é”™è¯¯: å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: $BACKUP_DIR/source.sql"
    exit 1
fi

# 1. ç¡®è®¤å›æ»š
read -p "ç¡®è®¤è¦å›æ»šåˆ° $BACKUP_DIR å—ï¼Ÿ(yes/no): " confirm
if [ "$confirm" != "yes" ]; then
    echo "å–æ¶ˆå›æ»š"
    exit 0
fi

# 2. åœæ­¢åº”ç”¨
echo "1. åœæ­¢åº”ç”¨..."
systemctl stop alkaid-swoole

# 3. æ¢å¤æ•°æ®åº“
echo "2. æ¢å¤æ•°æ®åº“..."
mysql -u root -p alkaid < $BACKUP_DIR/source.sql

# 4. å¯åŠ¨åº”ç”¨
echo "3. å¯åŠ¨åº”ç”¨..."
systemctl start alkaid-swoole

echo "========================================="
echo "å›æ»šå®Œæˆï¼"
echo "========================================="
```

## ğŸ†š ä¸ NIUCLOUD æ•°æ®è¿ç§»å¯¹æ¯”

| ç‰¹æ€§ | AlkaidSYS | NIUCLOUD | ä¼˜åŠ¿ |
|------|-----------|----------|------|
| **è¿ç§»å·¥å…·** | å®Œæ•´å·¥å…·é“¾ | æ‰‹åŠ¨è¿ç§» | âœ… æ›´è‡ªåŠ¨åŒ– |
| **æ•°æ®éªŒè¯** | è‡ªåŠ¨éªŒè¯ | æ‰‹åŠ¨éªŒè¯ | âœ… æ›´å¯é  |
| **å›æ»šæ–¹æ¡ˆ** | ä¸€é”®å›æ»š | æ‰‹åŠ¨å›æ»š | âœ… æ›´å¿«é€Ÿ |
| **å¢é‡åŒæ­¥** | æ”¯æŒ | ä¸æ”¯æŒ | âœ… æ›´çµæ´» |
| **æ–‡æ¡£å®Œå–„** | å®Œæ•´æ–‡æ¡£ | åŸºç¡€æ–‡æ¡£ | âœ… æ›´è¯¦ç»† |

---

**æœ€åæ›´æ–°**: 2025-01-19
**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**ç»´æŠ¤è€…**: AlkaidSYS æ¶æ„å›¢é˜Ÿ

